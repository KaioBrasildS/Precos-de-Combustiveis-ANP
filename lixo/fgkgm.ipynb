{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score\n",
    "from timeseriesmetrics import theil\n",
    "\n",
    "def computeAccuracyModels(model_name, city_name, y_pred, y_true):\n",
    "    \"\"\"\n",
    "    Calcula as métricas Theil e R² para um modelo e localidade e atualiza o DataFrame consolidado.\n",
    "    Adiciona apenas as colunas para o modelo especificado, sem recriar as linhas de localidades já existentes.\n",
    "    \"\"\"\n",
    "    global df_metrics  # DataFrame consolidado de métricas\n",
    "\n",
    "    # Garantir que y_pred e y_true são arrays numpy ou pandas\n",
    "    y_pred = y_pred.values if isinstance(y_pred, pd.Series) else y_pred\n",
    "    y_true = y_true.values if isinstance(y_true, pd.Series) else y_true\n",
    "\n",
    "    # Cálculo das métricas\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    theil_stat = theil(y_true, y_pred)\n",
    "\n",
    "    # Nome das colunas dinâmicas para este modelo\n",
    "    r2_col_name = f'R2_{model_name}'\n",
    "    theil_col_name = f'Theil_{model_name}'\n",
    "\n",
    "    # Se a localidade já existe no DataFrame, adiciona/atualiza as colunas para o modelo\n",
    "    if city_name in df_metrics['Localidade'].values:\n",
    "        df_metrics.loc[df_metrics['Localidade'] == city_name, r2_col_name] = r2\n",
    "        df_metrics.loc[df_metrics['Localidade'] == city_name, theil_col_name] = theil_stat\n",
    "    else:\n",
    "        # Caso a localidade não exista, levanta um erro\n",
    "        raise ValueError(f\"Localidade '{city_name}' não encontrada no DataFrame. Adicione-a antes de usar a função.\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Função para aplicar Random Walk em múltiplas séries temporais\n",
    "\n",
    "def random_walk_forecast_multiple(series_dict):\n",
    "    forecast_results = {}\n",
    "    \n",
    "    for city_name, series in series_dict.items():\n",
    "\n",
    "        # Previsão usando Random Walk\n",
    "        y_forecast = series.shift(1)\n",
    "        y_forecast.iloc[0] = series.iloc[0]  # Ajuste o primeiro valor para evitar NaN\n",
    "        \n",
    "        # Armazenar as previsões separadas para cada cidade\n",
    "        forecast_results[city_name] = y_forecast\n",
    "    \n",
    "    return forecast_results\n",
    "\n",
    "\n",
    "# Função para calcular os lags significantes\n",
    "\n",
    "from statsmodels.tsa.stattools import pacf\n",
    "from statsmodels.graphics.tsaplots import plot_acf,plot_pacf\n",
    "\n",
    "def getSignificantLags(y, nLags = 5, alpha=0.05):\n",
    "    Pacf, Pacf_intervalos =  pacf(x=y, nlags=nLags, alpha=alpha)\n",
    "   \n",
    "    significantLags = []\n",
    "    for i in range(1, len(Pacf)):\n",
    "        # print(pac[i], pac_ci[i][0], pac_ci[i][1])\n",
    "        if Pacf[i] < Pacf_intervalos[i][0] - Pacf[i] or Pacf[i] > Pacf_intervalos[i][1] - Pacf[i]:\n",
    "            significantLags.append(i)\n",
    "    print('Lags Significantes:', significantLags)\n",
    "    return significantLags\n",
    "\n",
    "\n",
    "# Processa os resíduos de previsão e identifica os lags mais relevantes.    \n",
    "\n",
    "def process_residuals_print(y_true, y_forecast, city_name, nLags=5, alpha=0.07):\n",
    "    \"\"\"\n",
    "    # Processa os resíduos de previsão e identifica os lags mais relevantes.\n",
    "    \n",
    "    Parâmetros:\n",
    "    - y_true: Série original.\n",
    "    - y_forecast: Previsões da série.\n",
    "    - city_name: Nome da cidade.\n",
    "    - nLags: Número máximo de lags a serem analisados (padrão: 5).\n",
    "    - alpha: Nível de significância para cálculo do PACF (padrão: 0.05).\n",
    "    \n",
    "    Retorno:\n",
    "    - city_name: Nome da cidade.\n",
    "    - significantLags: Lista com os lags significativos.\n",
    "    \"\"\"\n",
    "    # Calcular resíduos (erro entre a série original e a previsão)\n",
    "    residuos_serie = pd.DataFrame({\n",
    "        'residuos': y_true - y_forecast\n",
    "    }, index=y_true.index)\n",
    "    \n",
    "    # Identificar lags mais relevantes\n",
    "    significantLags = getSignificantLags(residuos_serie['residuos'], nLags=nLags, alpha=alpha)\n",
    "    \n",
    "    return city_name, significantLags    \n",
    "\n",
    "\n",
    "# Função para calcular resíduos, variáveis lagged e escalonamento para cada cidade\n",
    "\n",
    "def process_residuals(y_true, y_forecast):\n",
    "    # Calcular resíduos (erro entre a série original e a previsão)\n",
    "    residuos_serie = y_true - y_forecast\n",
    "    # Construir variáveis lagged para previsão\n",
    "    X_residual = residuos_serie.shift(1)  # Resíduo defasado em um ponto\n",
    "    # Ajustar os valores iniciais ausentes para consistência\n",
    "    X_residual.iloc[0] = X_residual.iloc[1]  # Ajustar o primeiro valor\n",
    "\n",
    "    X_residual.columns = ['Lag_1']\n",
    "\n",
    "\n",
    "    y_residual = residuos_serie.loc[X_residual.index]  # Valores dos resíduos\n",
    "\n",
    "    return X_residual, y_residual\n",
    "\n",
    "\n",
    "\n",
    "# Função para aplicar a busca Bayesiana e salvar os melhores parâmetros\n",
    "\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from ridge_sgd_kernel import RidgeSGDKernelTorch\n",
    "from ridge_sgd_kernel import RidgeSGDKernelTorch\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "import numpy as np\n",
    "\n",
    "class RidgeSGDKernelTorchWrapper(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, eta=0.01, c=0.01, sigma=1.0):\n",
    "        self.eta = eta\n",
    "        self.c = c\n",
    "        self.sigma = sigma\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Inicializar o modelo\n",
    "        self.model = RidgeSGDKernelTorch(eta=self.eta, c=self.c, sigma=self.sigma)\n",
    "        # Treinar online\n",
    "        for x_new, y_new in zip(X, y):\n",
    "            self.model.partial_fit(x_new, y_new)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Realizar previsões\n",
    "        return np.array([self.model.predict(x) for x in X])\n",
    "\n",
    "\n",
    "def apply_bayes_search_for_city(city, X, y, param_grid):\n",
    "    # Criar o modelo de busca Bayesiana\n",
    "    bayes_search = BayesSearchCV(\n",
    "        RidgeSGDKernelTorchWrapper(),\n",
    "        search_spaces=param_grid,\n",
    "        n_iter=30,\n",
    "        cv=TimeSeriesSplit(n_splits=3),\n",
    "        scoring='neg_mean_squared_error',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # Realizar a busca\n",
    "    bayes_search.fit(X.values, y.values)\n",
    "\n",
    "    # Obter os melhores parâmetros da busca\n",
    "    best_params = bayes_search.best_params_\n",
    "\n",
    "    # Criar e treinar o modelo com os melhores parâmetros encontrados\n",
    "    ridge_sgd_torch_best = RidgeSGDKernelTorch(\n",
    "        eta=best_params['eta'],\n",
    "        c=best_params['c'],\n",
    "        sigma=best_params['sigma']\n",
    "    )\n",
    "\n",
    "    # Lista para armazenar previsões\n",
    "    y_pred_best = []\n",
    "\n",
    "    # Treinar e prever de forma online com os dados\n",
    "    for x_new, y_new in zip(X.values, y.values):\n",
    "        ridge_sgd_torch_best.partial_fit(x_new, y_new)\n",
    "        prediction = ridge_sgd_torch_best.predict(x_new)\n",
    "        y_pred_best.append(prediction)\n",
    "\n",
    "    # Previsões indexadas\n",
    "    y_pred_bayes_indexed = pd.Series(y_pred_best, index=y.index)\n",
    "\n",
    "    return y_pred_bayes_indexed, best_params\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from norm import RidgeSGDKernelTorchDict\n",
    "import torch\n",
    "def apply_model_and_plot(X_residual, y_residual, best_params):\n",
    "    # Converter os dados em dicionários para serem compatíveis com o modelo\n",
    "    X_residual_dict = {idx: x for idx, x in zip(y_residual.index, X_residual.values)}\n",
    "    y_residual_dict = {idx: y for idx, y in zip(y_residual.index, y_residual.values)}\n",
    "\n",
    "    # Instanciar o modelo com os melhores parâmetros encontrados para a cidade\n",
    "    ridge_sgd_torch = RidgeSGDKernelTorchDict(eta=best_params['eta'], c=best_params['c'], sigma=best_params['sigma'])\n",
    "\n",
    "    # Dicionário para armazenar previsões\n",
    "    y_pred = {}\n",
    "\n",
    "    # Treinar e prever de forma online com os dados residuais\n",
    "    for idx in X_residual_dict.keys():\n",
    "        x_new = X_residual_dict[idx]\n",
    "        y_new = y_residual_dict[idx]\n",
    "\n",
    "        # Atualizar o modelo com o novo ponto e obter a previsão diretamente\n",
    "        pred_n = ridge_sgd_torch.partial_fit(x_new, y_new, idx)\n",
    "\n",
    "        # Garantir que `pred_n` seja convertido corretamente para escalar\n",
    "        if isinstance(pred_n, torch.Tensor):\n",
    "            y_pred[idx] = pred_n.item()\n",
    "        else:\n",
    "            y_pred[idx] = pred_n\n",
    "\n",
    "    # Converter as previsões em um pandas.Series para facilitar o plot\n",
    "    y_pred_series = pd.Series(y_pred).sort_index()\n",
    "    y_residual_series = pd.Series(y_residual_dict).sort_index()\n",
    "\n",
    "    return y_residual_series, y_pred_series\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
