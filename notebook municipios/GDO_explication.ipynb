{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def gaussian_kernel(x1, x2, sigma):\n",
    "    return torch.exp(-torch.norm(x1 - x2) ** 2 / (2 * sigma ** 2))\n",
    "```\n",
    "\n",
    "O kernel Gaussiano (ou RBF, Radial Basis Function) mede a similaridade entre dois vetores `x1` e `x2`. Ele funciona da seguinte maneira:\n",
    "\n",
    "- `torch.norm(x1 - x2)`: calcula a distância Euclidiana entre os vetores.\n",
    "- `sigma`: controla a suavidade da função kernel. Quanto menor o `sigma`, mais \"local\" é o efeito do kernel.\n",
    "- `torch.exp(-dist / (2 * sigma ** 2))`: converte a distância em uma medida de similaridade. Quanto mais próximos `x1` e `x2`, maior será o valor retornado pelo kernel, próximo a `1`. Se estiverem distantes, o valor será próximo a `0`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class RidgeSGDKernelTorch(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, eta=0.01, c=1.0, sigma=1.0):\n",
    "        self.eta = eta\n",
    "        self.c = c\n",
    "        self.sigma = sigma\n",
    "        self.alpha = None\n",
    "        self.X_train_tensor = None\n",
    "```\n",
    "\n",
    "Esta classe implementa um regressor customizado:\n",
    "\n",
    "- `eta`: taxa de aprendizado usada na atualização dos pesos durante o treinamento (descida de gradiente).\n",
    "- `c`: parâmetro de regularização para penalizar grandes valores de `alpha`, ajudando a evitar o sobreajuste.\n",
    "- `sigma`: parâmetro do kernel Gaussiano, controlando o alcance da influência dos pontos.\n",
    "- `alpha`: vetor de coeficientes que o modelo ajusta online, ou seja, conforme novos dados de treino chegam.\n",
    "- `X_train_tensor`: armazena os dados de treinamento para calcular o kernel em cada novo exemplo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def fit(self, X, y):\n",
    "    self.alpha = None\n",
    "    self.X_train_tensor = None\n",
    "    for x_new, y_new in zip(X, y):\n",
    "        self.partial_fit(x_new, y_new)\n",
    "    return self\n",
    "\n",
    "```\n",
    "O método `fit` percorre todos os pares `(x_new, y_new)` do conjunto de dados e chama `partial_fit` para treinar o modelo de forma incremental. Esse processo ajusta os coeficientes `alpha` com base em cada novo ponto.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def partial_fit(self, x_new, y_new):\n",
    "    if self.X_train_tensor is None:\n",
    "        self.X_train_tensor = torch.tensor([x_new], dtype=torch.float32)\n",
    "        self.alpha = torch.zeros(1, dtype=torch.float32)\n",
    "    else:\n",
    "        self.X_train_tensor = torch.vstack([self.X_train_tensor, torch.tensor(x_new, dtype=torch.float32)])\n",
    "        self.alpha = torch.cat([self.alpha, torch.zeros(1)])\n",
    "\n",
    "    n_samples = self.X_train_tensor.shape[0]\n",
    "\n",
    "    if n_samples > 1:\n",
    "        kernels = torch.tensor([gaussian_kernel(self.X_train_tensor[i], self.X_train_tensor[-1], self.sigma)\n",
    "                                for i in range(n_samples - 1)])\n",
    "        pred_n = torch.dot(self.alpha[:n_samples - 1], kernels)\n",
    "    else:\n",
    "        pred_n = 0\n",
    "\n",
    "    error = y_new - pred_n\n",
    "\n",
    "    self.alpha[:n_samples - 1] = (1 - self.eta * self.c) * self.alpha[:n_samples - 1]\n",
    "    self.alpha[n_samples - 1] = self.eta * error\n",
    "\n",
    "```\n",
    "\n",
    "Este método `partial_fit` realiza um ajuste online (incremental) no modelo, processando um único par `x_new`, `y_new` de cada vez. Aqui está o que cada parte do código faz:\n",
    "\n",
    "### Armazenamento dos Dados de Treinamento Incremental\n",
    "\n",
    "- Se `self.X_train_tensor` está vazio (ou seja, é o primeiro ponto a ser processado), inicializamos esse tensor com `x_new` e criamos um vetor `alpha` de zeros, com um valor.\n",
    "- Se não está vazio, acrescentamos `x_new` a `self.X_train_tensor` e estendemos `alpha` com um novo zero. Dessa forma, todos os dados recebidos são armazenados incrementadamente, um por vez.\n",
    "\n",
    "### Predição Incremental\n",
    "\n",
    "- `n_samples` guarda o número total de amostras no tensor de treinamento atual.\n",
    "- Se há mais de uma amostra, calculamos a similaridade entre `x_new` (última amostra) e cada amostra anterior usando o `gaussian_kernel`.\n",
    "- `pred_n` é a predição para `x_new`, calculada como a combinação linear das entradas de `alpha` correspondentes às amostras anteriores e seus valores de similaridade (kernels).\n",
    "- Se há apenas uma amostra, `pred_n` é `0`.\n",
    "\n",
    "### Erro e Atualização de Alpha\n",
    "\n",
    "- `error` representa o erro da predição atual: `error = y_new - pred_n`.\n",
    "- As entradas anteriores de `alpha` são atualizadas para refletir o erro com base na taxa de regularização `c` e taxa de aprendizado `eta`: `(1 - self.eta * self.c) * self.alpha[:n_samples - 1]`.\n",
    "- A última entrada de `alpha` é atualizada para a proporção do erro atual `self.eta * error`, associando o erro atual ao ponto mais recente, `x_new`.\n",
    "\n",
    "Assim, esse método ajusta o modelo de forma incremental, acumulando e atualizando os pesos `alpha` com base em cada nova amostra recebida.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
